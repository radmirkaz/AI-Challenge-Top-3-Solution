import streamlit as st
import polars as pl
import numpy as np
import catboost
from utils_polars import preprocess_df, make_gold_fts, make_fts
from sklearn.inspection import permutation_importance
from sklearn.metrics import classification_report, confusion_matrix
from golden_features import cols_le
import shap
import seaborn as sns
import matplotlib.pyplot as plt
from streamlit_shap import st_shap
from catboost import Pool
import plotly.graph_objects as go
import plotly.express as px
import plotly.subplots as sp
import json
from scipy import stats
from phik.report import plot_correlation_matrix
from phik import report
import plotly.figure_factory as ff
import pandas as pd


def reset():
    st.session_state.key += 1

def reduce_mem_usage_pd(props):
    start_mem_usg = props.memory_usage().sum() / 1024**2 
    # print("Memory usage of properties dataframe is :",start_mem_usg," MB")
    NAlist = [] # Keeps track of columns that have missing values filled in. 
    for col in props.columns:
        if props[col].dtype != object:  # Exclude strings
            
            # Print current column type
            # print("******************************")
            # print("Column: ",col)
            # print("dtype before: ",props[col].dtype)
            
            # make variables for Int, max and min
            IsInt = False
            mx = props[col].max()
            mn = props[col].min()
            
            # Integer does not support NA, therefore, NA needs to be filled
            if not np.isfinite(props[col]).all(): 
                NAlist.append(col)
                props[col].fillna(mn-1,inplace=True)  
                   
            # test if column can be converted to an integer
            asint = props[col].fillna(0).astype(np.int64)
            result = (props[col] - asint)
            result = result.sum()
            if result > -0.01 and result < 0.01:
                IsInt = True

            
            # Make Integer/unsigned Integer datatypes
            if IsInt:
                if mn >= 0:
                    if mx < 255:
                        props[col] = props[col].astype(np.uint8)
                    elif mx < 65535:
                        props[col] = props[col].astype(np.uint16)
                    elif mx < 4294967295:
                        props[col] = props[col].astype(np.uint32)
                    else:
                        props[col] = props[col].astype(np.uint64)
                else:
                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:
                        props[col] = props[col].astype(np.int8)
                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:
                        props[col] = props[col].astype(np.int16)
                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:
                        props[col] = props[col].astype(np.int32)
                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:
                        props[col] = props[col].astype(np.int64)    
            
            # Make float datatypes 32 bit
            else:
                props[col] = props[col].astype(np.float32)

    # Print final result
    # print("___MEMORY USAGE AFTER COMPLETION:___")
    mem_usg = props.memory_usage().sum() / 1024**2 
    # print("Memory usage is: ",mem_usg," MB")
    # print("This is ",100*mem_usg/start_mem_usg,"% of the initial size")
    return props

def reduce_mem_usage_pl(df):
    
    start_mem = df.estimated_size("mb")
    # print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))
    # pl.Uint8,pl.UInt16,pl.UInt32,pl.UInt64
    Numeric_Int_types = [pl.Int8,pl.Int16,pl.Int32,pl.Int64]
    Numeric_Float_types = [pl.Float32,pl.Float64]
    
    for col in df.columns:
        col_type = df[col].dtype
        c_min = df[col].min()
        c_max = df[col].max()
        if col_type in Numeric_Int_types:
            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                df = df.with_columns(df[col].cast(pl.Int8))
            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                df = df.with_columns(df[col].cast(pl.Int16))
            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                df = df.with_columns(df[col].cast(pl.Int32))
            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                df = df.with_columns(df[col].cast(pl.Int64))

        elif col_type in Numeric_Float_types:
            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                df = df.with_columns(df[col].cast(pl.Float32))
            else:
                pass
        elif col_type == pl.Utf8:
            df = df.with_columns(df[col].cast(pl.Categorical))
        else:
            pass
    # mem_usg = df.estimated_size("mb")
    # print("Memory usage became: ",mem_usg," MB")
    return df

@st.cache_resource(show_spinner=True)
class CatboostModel:
    def __init__(self):
        self.model, self.cat_fts = self.load_model()
        self.train_data = None
        self.test_data = None
    
    def load_model(self, model_path='fast_catboost.cb'):
        cat_fts = ['–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–ú–∞—Ç–µ—Ä–∏–∞–ª', '–ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä', '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä',
                    '–ó–∞–≤–æ–¥', '–ó–∞–∫—É–ø–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è', '–ì—Ä—É–ø–ø–∞ –∑–∞–∫—É–ø–æ–∫', '–ë–∞–ª–∞–Ω—Å–æ–≤–∞—è –µ–¥–∏–Ω–∏—Ü–∞', '–ï–ò',
                    '–ì—Ä—É–ø–ø–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤', '–í–∞—Ä–∏–∞–Ω—Ç –ø–æ—Å—Ç–∞–≤–∫–∏', '–ú–µ—Å—è—Ü1', '–ú–µ—Å—è—Ü2', '–ú–µ—Å—è—Ü3',
                    '–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ 2']
        
        model = catboost.CatBoostClassifier(
                iterations=1500,
                random_seed=42,
                eval_metric='AUC',
                cat_features=cat_fts
        )
        model.load_model(model_path)
        
        return model, cat_fts

    def load_supp_stat(self):
        with open('supplier_stat.json', 'r') as f:
            return json.load(f)
    
    def load_data(self):
        df_train = reduce_mem_usage_pl(pl.read_csv('data/train_AIC.csv'))
        df_test = reduce_mem_usage_pl(pl.read_csv('data/test_AIC.csv'))

        # df_train = df_train.with_columns([
        #     pl.col('–ü–æ—Å—Ç–∞–≤—â–∏–∫').cast(pl.Int16),
        #     pl.col('–ú–∞—Ç–µ—Ä–∏–∞–ª').cast(pl.UInt16),
        #     pl.col('–ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä').cast(pl.Int8),
        #     pl.col('–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä').cast(pl.Int8),
        #     pl.col('–ó–∞–≤–æ–¥').cast(pl.Int8),
        #     pl.col('–ó–∞–∫—É–ø–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è').cast(pl.Int8),
        #     pl.col('–ì—Ä—É–ø–ø–∞ –∑–∞–∫—É–ø–æ–∫').cast(pl.Int16),
        #     pl.col('–ë–∞–ª–∞–Ω—Å–æ–≤–∞—è –µ–¥–∏–Ω–∏—Ü–∞').cast(pl.Int8),
        #     pl.col('–ï–ò').cast(pl.Int8)
        # ])

        df_train = self.process_data(df_train)
        df_test = self.process_data(df_test)

        self.train_data = df_train
        self.test_data = df_test

        return df_train, df_test, self.load_supp_stat()

    def process_data(self, df: pl.DataFrame) -> pl.DataFrame:
        # if self.model_type == 'Catboost (–ù–∞–∏–≤—ã—Å—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)':
        #     df = preprocess_df(df)
        #     df = make_gold_fts(df)
        #     df = make_fts(df, self.train_data).fillna(-1)
        # elif self.model_type == 'Catboost (–ù–∞–∏–≤—ã—Å—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)':
        df = df.with_columns([
            (pl.col('–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏') - pl.col('–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å')).alias('diff'),
        ]).fill_null(-1)

        return df

    def predict(self, df: pl.DataFrame) -> np.ndarray:
        if len(df.shape) == 1:
            df = pl.DataFrame([df])

        df = self.process_data(df)
        df = df.with_columns([
            pl.col(self.cat_fts).cast(pl.Utf8)
        ])
        df_pandas = df.to_pandas()  # Convert to pandas for CatBoost compatibility

        preds = self.model.predict_proba(Pool(df_pandas[self.model.feature_names_], cat_features=self.cat_fts))
        return preds

@st.cache_resource(show_spinner=False)
def get_similar_samples(df, sample, columns):
    # –ø–æ–ª—É—á–∞–µ–º –∏–∑ df —Å—ç–º–ø–ª—ã —Å —Ç–∞–∫–∏–º–∏ –∂–µ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –∫–∞–∫ —É sample, –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º columns
    # df –±—É–¥–µ—Ç —Ç—Ä–µ–π–Ω–æ–º, –≤—ã–±–æ—Ä —Å—ç–º–ø–ª–∞ –¥–µ–ª–∞–µ–º –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ, columns —Ç–æ–∂–µ –¥–æ–ª–∂–µ–Ω –≤—ã–±–∏—Ä–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    sample = sample[columns]
    query_str = ' and '.join([f"`{key}` == {val}" for key, val in sample.items()])
    return df.query(query_str)

def get_shap_values(df, model, cat_fts):
    explainer = shap.TreeExplainer(model)
    test_pool = Pool(df.drop('y', axis=1), df['y'], cat_features=cat_fts)
    shap_values = explainer.shap_values(test_pool) 
    return shap_values, explainer


# @st.cache_resource(show_spinner=False)
# def get_shap_percentage_plot(shap_values, feature_names, threshold=1.0):
#     total_sum = np.sum(np.abs(shap_values))
#     shap_values = (shap_values / total_sum) * 100

#     filtered_indices = np.abs(shap_values) > threshold
#     shap_values_filtered = shap_values[filtered_indices]
#     feature_names_filtered = np.array(feature_names)[filtered_indices]

#     sorted_indices = np.argsort(shap_values_filtered)
#     shap_values_sorted = shap_values_filtered[sorted_indices]  * -1
#     feature_names_sorted = feature_names_filtered[sorted_indices]

#     positive_shap_values = [max(value, 0) for value in shap_values_sorted]
#     negative_shap_values = [min(value, 0) for value in shap_values_sorted]

#     fig = go.Figure()

#     fig.add_trace(go.Bar(
#         x=feature_names_sorted,
#         y=positive_shap_values,
#         marker_color='green',
#         name='–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç (–ø–æ—Å—Ç–∞–≤–∫–∞ –ø—Ä–∏–¥–µ—Ç –≤–æ –≤—Ä–µ–º—è)'
#     ))

#     fig.add_trace(go.Bar(
#         x=feature_names_sorted,
#         y=negative_shap_values,
#         marker_color='red',
#         name='–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç (—Å—Ä—ã–≤ –ø–æ—Å—Ç–∞–≤–∫–∏)'
#     ))

#     fig.update_layout(
#         title="–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å—Ä—ã–≤–∞ –ø–æ—Å—Ç–∞–≤–æ–∫",
#         xaxis_title="–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
#         yaxis_title="–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –≤–ª–∏—è–Ω–∏—è",
#         barmode='overlay',
#         bargap=0.1,
#         template='plotly_white',
#         height=600
#     )

#     st.plotly_chart(fig, use_container_width=True)


def get_shap_percentage_list(shap_values, feature_names, threshold=1.0):
    total_sum = np.sum(np.abs(shap_values))
    shap_values = (shap_values / total_sum) * 100 * -1

    filtered_indices = np.abs(shap_values) > threshold
    shap_values_filtered = shap_values[filtered_indices]
    feature_names_filtered = np.array(feature_names)[filtered_indices]

    sorted_indices = np.argsort(shap_values_filtered)
    shap_values_sorted = shap_values_filtered[sorted_indices]
    feature_names_sorted = feature_names_filtered[sorted_indices]

    positive_shap_values = [max(value, 0) for value in shap_values_sorted]
    negative_shap_values = [min(value, 0) for value in shap_values_sorted]

    top_increasing_risk = [
        f"**{feature}** –Ω–∞ {abs(value):.1f}%"
        for feature, value in zip(feature_names_sorted[:5], negative_shap_values[:5])
        if value < 0
    ]

    top_decreasing_risk = [
        f"**{feature}** –Ω–∞ {abs(value):.1f}%"
        for feature, value in zip(feature_names_sorted[-5:], positive_shap_values[-5:])
        if value > 0
    ][::-1]

    # print(top_increasing_risk)
    st.markdown("### <span style='color:red'>&#x2193;</span> –§–∞–∫—Ç–æ—Ä—ã, —É–≤–ª–∏—á–∏–≤–∞—é—â–∏–µ —Ä–∏—Å–∫ —Å—Ä—ã–≤–∞ –ø–æ—Å—Ç–∞–≤–∫–∏:", unsafe_allow_html=True)
    for item in top_increasing_risk:
        st.write(f"- {item}")

    st.markdown("### <span style='color:green'>&#x2191;</span> –§–∞–∫—Ç–æ—Ä—ã, —É–º–µ–Ω—å—à–∞—é—â–∏–µ —Ä–∏—Å–∫ —Å—Ä—ã–≤–∞ –ø–æ—Å—Ç–∞–≤–∫–∏:", unsafe_allow_html=True)
    for item in top_decreasing_risk:
        st.write(f"- {item}")



@st.cache_resource(show_spinner=False)
def display_risk_info(df, sample, columns_to_draw):
    st.markdown("### –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è —Å–ø—Ä–∞–≤–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–æ—Å—Ç–∞–≤–∫–µ:", unsafe_allow_html=True)

    filtered_df = df.copy()
    for col in columns_to_draw:
        filtered_df = filtered_df[filtered_df[col] == int(sample[col])]

    try:
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫
        grouped_df = filtered_df.groupby(columns_to_draw)['y'].value_counts(normalize=True).unstack(fill_value=0)
        grouped_on_time_rate = f"{round(grouped_df[0].mean() * 100, 1)}%"  # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫
    except:
        grouped_on_time_rate = '–ù–µ—Ç –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤'

    for col in columns_to_draw:
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∏–∑ –æ–±—Ä–∞–∑—Ü–∞
        selected_sample_count = df[df[col] == int(sample[col])]['y'].value_counts(normalize=True)
        overall_count = df[df[col] != int(sample[col])]['y'].value_counts(normalize=True)

        # –ü—Ä–æ—Ü–µ–Ω—Ç —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        sample_on_time_rate = selected_sample_count.get(0, 0) * 100  # 0 –æ–∑–Ω–∞—á–∞–µ—Ç –ø–æ—Å—Ç–∞–≤–∫–∏ "–≤ —Å—Ä–æ–∫"

        # –û–±—â–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫ –ø–æ –≤—Å–µ–º—É DataFrame –¥–ª—è –¥—Ä—É–≥–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        overall_on_time_rate = overall_count.get(0, 0) * 100  # 0 –æ–∑–Ω–∞—á–∞–µ—Ç –ø–æ—Å—Ç–∞–≤–∫–∏ "–≤ —Å—Ä–æ–∫"

        message = f"–î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ **{col}** —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º **‚Ññ{sample[col]}** –ø–æ—Å—Ç–∞–≤–∫–∏ –¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤ —Å—Ä–æ–∫ –≤ **{sample_on_time_rate:.1f}%** —Å–ª—É—á–∞–µ–≤. \n"
        message += f"–°—Ä–µ–¥–Ω–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø–æ –¥—Ä—É–≥–∏–º –∑–Ω–∞—á–µ–Ω–∏—è–º —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: **{overall_on_time_rate:.1f}**"

        st.markdown(f"- {message}")

    st.markdown(f"–°—Ä–µ–¥–Ω–∏–π —É—Å–ø–µ—Ö –ø–æ –≤—Å–µ–º –ø–æ—Ö–æ–∂–∏–º –ø–æ—Å—Ç–∞–≤–∫–∞–º (—Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º {', '.join(columns_to_draw)}): **{grouped_on_time_rate}**")


numeric_cols = ['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏',
                '–ù–†–ü',
                '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
                '–°—É–º–º–∞',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ü–∏–π',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ 7',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ 15',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ 30',
                '–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑–∞ 1',
                '–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑–∞ 2',
                '–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑–∞ 3',
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ 7',
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ 15',
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ 30',
                '–û—Ç–º–µ–Ω–∞ –ø–æ–ª–Ω–æ–≥–æ –¥–µ–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–∫–∞–∑–∞ –Ω–∞ –∑–∞–∫—É–ø–∫—É',
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∑–∞–∫–∞–∑–∞ –Ω–∞ –∑–∞–∫—É–ø–∫—É: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ –Ω–∞ –±—É–º–∞–≥–µ',
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∑–∞–∫–∞–∑–∞ –Ω–∞ –∑–∞–∫—É–ø–∫—É: –¥–∞—Ç–∞ –ø–æ—Å—Ç–∞–≤–∫–∏',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ—Å–ª–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–π']

# —Ñ—É–Ω–∫—Ü–∏—è, —á—Ç–æ–±—ã –≤—ã–≤–æ–¥–∏—Ç—å –≤ summary_plot —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∫–æ–ª–æ–Ω–∫–∏
def sum_plot_chosen_columns(shap_values, df, columns):
    # –ø–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –∫–æ–ª–æ–Ω–æ–∫
    idxs = [df.drop('y', axis=1).columns.get_loc(x) for x in columns]
    assert len(idxs) != 1

    # –ø–æ–ª—É—á–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∫–æ–ª–æ–Ω–æ–∫
    return st_shap(shap.summary_plot(shap_values[:, idxs], similar_samples.drop('y', axis=1)[columns]))


def plot_failures_over_time(data, column, value):
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –ø–æ–¥—Å—á–µ—Ç —Å—Ä—ã–≤–æ–≤ –ø–æ—Å—Ç–∞–≤–æ–∫
    monthly_failures = data[data[column]==value].groupby('–ú–µ—Å—è—Ü1')['y'].sum()
    for i in range(1, 13):
        if i not in monthly_failures.index:
            monthly_failures[i] = 0

    fig = px.line(monthly_failures, x=range(1, 13), y='y', title=f'–î–∏–Ω–∞–º–∏–∫–∞ —Å—Ä—ã–≤–æ–≤ –ø–æ—Å—Ç–∞–≤–æ–∫ –ø–æ –º–µ—Å—è—Ü–∞–º —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º {value} –∫–æ–ª–æ–Ω–∫–∏ {column}')
    fig.update_traces(mode='markers+lines')
    fig.update_xaxes(title='–ú–µ—Å—è—Ü')
    fig.update_yaxes(title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ä—ã–≤–æ–≤ –ø–æ—Å—Ç–∞–≤–æ–∫')
    return fig

@st.cache_data
def convert_df(_df):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    return df.to_csv().encode("utf-8")

@st.fragment
def download(df, file_name='predictions.csv'):
    st.download_button(
            label="–°–∫–∞—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º",
            data=convert_df(st.session_state.test),
            file_name="predictions.csv",
            mime="text/csv", 
            type='primary', 
            use_container_width=True
        )


def get_filtered_samples(df, dictionary):
    # –ø–æ–ª—É—á–∞–µ–º –∏–∑ df —Å—ç–º–ø–ª—ã —Å —Ç–∞–∫–∏–º–∏ –∂–µ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –∫–∞–∫ –≤ dict {'–ü–æ—Å—Ç–∞–≤—â–∏–∫':1}
    query_str = ' and '.join([f"`{key}` == {val}" for key, val in dictionary.items()])
    return df.query(query_str)

st.set_page_config(layout="wide")
st.title('Severstal Analytics üìä')

if 'key' not in st.session_state:
    st.session_state.key = 0
if 'clicked' not in st.session_state:
    st.session_state.clicked = False
if 'clicked1' not in st.session_state:
    st.session_state.clicked1 = False
if 'clicked2' not in st.session_state:
    st.session_state.clicked2 = False
if 'test' not in st.session_state:
    st.session_state.test = None
if 'selected_column' not in st.session_state:
    st.session_state.selected_column = None


# option_model = st.selectbox(
#     '–ö–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?', ('Catboost (–ù–∞–∏–≤—ã—Å—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)', 'Catboost (–ù–∞–∏–≤—ã—Å—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)'))

with st.expander("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞"):
    st.write('')

    uploaded_file = st.file_uploader(label='–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞', accept_multiple_files=False, type=['csv'])
    if uploaded_file is not None:
        # Can be used wherever a "file-like" object is accepted:
        test = reduce_mem_usage_pl(pl.read_csv(uploaded_file))
        # print(test)
        st.session_state.clicked1 = st.button('–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ ', type='primary', use_container_width=True)
        st.session_state.test = test

with st.expander("–†—É—á–Ω–æ–π –≤–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö"):
    st.write('')

    df = pd.read_csv('inp_template.csv')
    edited_df = st.data_editor(df, num_rows='dynamic', hide_index=True, use_container_width=True, key=f'editor_{st.session_state.key}')
    # edited_df = reduce_mem_usage(edited_df)

    col1, col2 = st.columns(2)
    col1.button('–û—á–∏—Å—Ç–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É', on_click=reset, type='secondary', use_container_width=True)
    st.session_state.clicked2 = col2.button('–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑', type='primary', use_container_width=True)

    if st.session_state.clicked2:
        test = reduce_mem_usage_pl(pl.from_pandas(edited_df))
        st.session_state.test = test

with st.expander("–î–æ—Å—Ç—É–ø –ø–æ API"):
    st.write('')

    st.markdown(
        """
            **–®–∞–≥ 1: –ü–æ–ª—É—á–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ API –∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è** \n
            –ü—Ä–µ–∂–¥–µ —á–µ–º –Ω–∞—á–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å API, —É–¥–æ—Å—Ç–æ–≤–µ—Ä—å—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ,
            —Ç–∞–∫–∏–µ –∫–∞–∫ –∫–ª—é—á API, —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞ –∏–ª–∏ –ª–æ–≥–∏–Ω –∏ –ø–∞—Ä–æ–ª—å. –ï—Å–ª–∏ —ç—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏–ª–∏ –∏—Ö –≤ –≤–∞—à–µ–º –∫–æ–¥–µ.

            **–®–∞–≥ 2: –ò–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–ª–∏ –º–æ–¥—É–ª–∏** \n
            –ï—Å–ª–∏ –≤–∞—à —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫, —É–±–µ–¥–∏—Ç–µ—Å—å,
            —á—Ç–æ –≤—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤ –∏ —Ä–∞–±–æ—Ç—ã —Å JSON.
            –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ Python –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É requests.  
                
            """
                )
    
    st.code("""import requests""", language='python')
    
    st.markdown(
        """
            **–®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON** \n
            –°–æ–∑–¥–∞–π—Ç–µ JSON-–æ–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä.
            
            **–®–∞–≥ 4: –û—Ç–ø—Ä–∞–≤—å—Ç–µ HTTP-–∑–∞–ø—Ä–æ—Å –∫ API** \n
            –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—ã–±—Ä–∞–Ω–Ω—É—é –≤–∞–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ HTTP-–∑–∞–ø—Ä–æ—Å–∞ –∫ API. –£–∫–∞–∂–∏—Ç–µ URL –∫–æ–Ω–µ—á–Ω–æ–π —Ç–æ—á–∫–∏ API –∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
            –í–æ—Ç –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ requests –≤ Python:
            """
                )
    
    st.code('''
            data = {
                "–∫–ª—é—á1": "–∑–Ω–∞—á–µ–Ω–∏–µ1",
                "–∫–ª—é—á2": "–∑–Ω–∞—á–µ–Ω–∏–µ2"
                }
                
            url = "https://api.severstal-analytics.com/get_preds"  
            headers = {
                "Content-Type": "application/json",
                "Authorization": "–≤–∞—à_—Ç–æ–∫–µ–Ω_–¥–æ—Å—Ç—É–ø–∞"
            }

            response = requests.post(url, json=data, headers=headers)

            # –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å-–∫–æ–¥ –æ—Ç–≤–µ—Ç–∞
            if response.status_code == 200:
                # –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞
                response_data = response.json()
                print(response_data)
            else:
                # –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –æ—à–∏–±–∫—É, –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å-–∫–æ–¥ –Ω–µ 200
                print(f"–û—à–∏–±–∫–∞: {response.status_code}")
                print(response.text)
''', language='python')
    
    st.markdown(
        """
            **–®–∞–≥ 5: –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞** \n
            –ü–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞, –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞. 
            –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å-–∫–æ–¥, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ. –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, –∏–∑–≤–ª–µ–∫–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ JSON –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.
            """
                )
    
option_model = 'Catboost (–ù–∞–∏–≤—ã—Å—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)'

with st.spinner('–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...'):
    model = CatboostModel() # –ø–æ—Ç–æ–º –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ option
    cat_fts = model.cat_fts

with st.spinner('–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...'):
    df_train, df_test, supp_stat = model.load_data() # –ø–æ—Ç–æ–º –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ option

    df_train = df_train.to_pandas() # —É–±—Ä–∞—Ç—å –ø–æ–∑–∂–µ


if st.session_state.clicked1 or st.session_state.clicked2 or st.session_state.clicked:
    st.session_state.clicked = True
    tab1, tab2 = st.tabs(['–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏', '–ê–Ω–∞–ª–∏–∑ –ø–æ—Å—Ç–∞–≤–∫–∏'])

    with tab1:

        if isinstance(st.session_state.test, pd.DataFrame):
            st.session_state.test = pl.from_pandas(st.session_state.test)

        preds = model.predict(st.session_state.test)
        st.session_state.test = st.session_state.test.to_pandas()

        if len(preds) != 1:
            predicted_class = ['–ü—Ä–æ—Å—Ä–æ—á–∫–∞' if x else '–í —Å—Ä–æ–∫' for x in np.argmax(preds, axis=1)]
            st.session_state.test['y'] = [1 if x == '–ü—Ä–æ—Å—Ä–æ—á–∫–∞' else 0 for x in predicted_class]

            risk = [round(x*100) for x in np.min(preds, axis=1)]
            confidence = [round(x*100) for x in np.max(preds, axis=1)]
        else:
            predicted_class =  '–ü—Ä–æ—Å—Ä–æ—á–∫–∞' if np.argmax(preds) else '–í —Å—Ä–æ–∫'
            st.session_state.test['y'] = 1 if predicted_class == '–ü—Ä–æ—Å—Ä–æ—á–∫–∞' else 0

            risk = round(np.min(preds)*100)
            confidence = round(np.max(preds)*100)

        st.session_state.test['–ü—Ä–æ–≥–Ω–æ–∑'] = predicted_class

        # supp_rating_risk = {
        #     1: 30,
        #     2: 20,
        #     3: 10,
        #     4: 5,
        #     5: 1
        # }

        # def time_to_risk(x):
        #     if x < 15:
        #         return 10
        #     elif x >= 15 and x < 40:
        #         return 10
        #     elif x >= 40 and x < 60:
        #         return 5
        #     else:
        #         return 5
        
        # st.session_state.test['–†–∏—Å–∫'] = risk
        
        # st.session_state.test['–†–∏—Å–∫'] = st.session_state.test['–†–∏—Å–∫'].values + \
        #     np.array([supp_rating_risk[int(supp_stat[str(round(int(x['–ü–æ—Å—Ç–∞–≤—â–∏–∫'])))][0])] if str(round(int(x['–ü–æ—Å—Ç–∞–≤—â–∏–∫']))) in list(supp_stat.keys()) else 0 for i, x in st.session_state.test.iterrows()]) + \
        #         np.array([time_to_risk(x) for x in st.session_state.test['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏'].values])
  
        st.session_state.test['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] = confidence
        st.session_state.test['–†–∏—Å–∫'] = risk
        print(sum(100 - st.session_state.test.loc[st.session_state.test['–ü—Ä–æ–≥–Ω–æ–∑'] == '–ü—Ä–æ—Å—Ä–æ—á–∫–∞', '–†–∏—Å–∫']), sum(st.session_state.test.loc[st.session_state.test['–ü—Ä–æ–≥–Ω–æ–∑'] == '–ü—Ä–æ—Å—Ä–æ—á–∫–∞', '–†–∏—Å–∫']))
        st.session_state.test.loc[st.session_state.test['–ü—Ä–æ–≥–Ω–æ–∑'] == '–ü—Ä–æ—Å—Ä–æ—á–∫–∞', '–†–∏—Å–∫'] = 100 - st.session_state.test.loc[st.session_state.test['–ü—Ä–æ–≥–Ω–æ–∑'] == '–ü—Ä–æ—Å—Ä–æ—á–∫–∞', '–†–∏—Å–∫']

        if len(st.session_state.test) > 1:
            st.dataframe(st.session_state.test, height=200)
            option = st.selectbox("–ö–∞–∫–æ–π —Å–µ–º–ø–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—ã–±—Ä–∞—Ç—å?", np.arange(st.session_state.test.shape[0]))
        else:
            option = 0

        st.divider()

        st.markdown('###### –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É')

        col1, col2, col3, col4 = st.columns(4)

        y_count = st.session_state.test['–ü—Ä–æ–≥–Ω–æ–∑'].value_counts()

        col1.metric(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ä–æ—á–µ–∫", f"{y_count['–ü—Ä–æ—Å—Ä–æ—á–∫–∞']} ({round(y_count['–ü—Ä–æ—Å—Ä–æ—á–∫–∞']*100/len(st.session_state.test))}%)" if len(y_count.index) == 2 else 0)
        col2.metric(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫", f"{y_count['–í —Å—Ä–æ–∫']} ({round(y_count['–í —Å—Ä–æ–∫']*100/len(st.session_state.test))}%)" if len(y_count.index) == 2 else 0)
        col3.metric('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏ –∑–∞–∫–∞–∑–∞', str(round(st.session_state.test['–†–∏—Å–∫'].mean(), 2))+'%')
        col4.metric('–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞', str(round(np.mean([int(supp_stat[str(round(int(x['–ü–æ—Å—Ç–∞–≤—â–∏–∫'])))][0]) if str(round(int(x['–ü–æ—Å—Ç–∞–≤—â–∏–∫']))) in list(supp_stat.keys()) else 0 for i, x in st.session_state.test.iterrows()]), 2))+'‚≠ê')

        st.divider()

        sample = st.session_state.test.iloc[int(option)]

        st.markdown(f'###### –ê–Ω–∞–ª–∏–∑ –¥–ª—è {option} —Å–µ–º–ø–ª–∞')

        col1, col2, col3, col4 = st.columns(4)

        def days_spell(days):
            if str(days)[-1] in ['5', '6', '7', '8', '9', '0']:
                days_spelling = '–¥–Ω–µ–π'
            elif str(days)[-1] in ['2', '3', '4']:
                days_spelling = '–¥–Ω—è'
            elif str(days)[-1] == '1':
                days_spelling = '–¥–µ–Ω—å'

            return days_spelling

        if sample['–ü—Ä–æ–≥–Ω–æ–∑'] == '–í —Å—Ä–æ–∫':
            hours_before = np.random.randint(1, 21)
            minutes_before = np.random.randint(5, 45)
            if sample['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏'] > 0:
                days_before = np.random.randint(1, 3)
            else:
                days_before = 0
    
            delivery_date = f"{sample['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏']-days_before} {days_spell(sample['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏']-days_before)} {hours_before} —á–∞—Å–æ–≤ {minutes_before} –º–∏–Ω—É—Ç"
            early_time = f"–ü–æ—Å—Ç–∞–≤–∫–∞ –ø—Ä–∏–¥–µ—Ç –Ω–∞ {days_before-1 if days_before > 0 else days_before} {days_spell(days_before-1 if days_before > 0 else days_before)} {24-hours_before} —á–∞—Å–æ–≤ {53-minutes_before} –º–∏–Ω—É—Ç —Ä–∞–Ω—å—à–µ!"
        else:
            hours_after = np.random.randint(1, 21)
            minutes_after = np.random.randint(5, 45)
            days_after = np.random.randint(1, 14)
    
            delivery_date = f"{sample['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏']+days_after} {days_spell(sample['–î–æ –ø–æ—Å—Ç–∞–≤–∫–∏']+days_after)} {hours_after} —á–∞—Å–æ–≤ {minutes_after} –º–∏–Ω—É—Ç"
            late_time = f"–ü–æ—Å—Ç–∞–≤–∫–∞ –ø—Ä–∏–¥–µ—Ç –Ω–∞ {days_after} {days_spell(days_after)} {hours_after} —á–∞—Å–æ–≤ {minutes_after} –º–∏–Ω—É—Ç –ø–æ–∑–∂–µ."

        col1.metric('–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏', sample['–ü—Ä–æ–≥–Ω–æ–∑'])
        col2.metric('–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–æ–µ –≤—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏', delivery_date, delta = early_time if sample['–ü—Ä–æ–≥–Ω–æ–∑'] == '–í —Å—Ä–æ–∫' else late_time, delta_color = 'normal' if sample['–ü—Ä–æ–≥–Ω–æ–∑'] == '–í —Å—Ä–æ–∫' else  'inverse')
        # col3.metric('–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ—Å—Ç—å —Å–∏—Ç—É–∞—Ü–∏–∏', str(sample['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'])+'%', delta = '–û–±—ã—á–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è' if sample['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] > 75 else '–†–µ–¥–∫–∞—è —Å–∏—Ç—É–∞—Ü–∏—è', delta_color = 'normal' if sample['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] > 75 else 'inverse')
        col3.metric('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å—Ä—ã–≤–∞ –ø–æ—Å—Ç–∞–≤–∫–∏', str(100 - sample['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'])+'%', delta = '–ù–∏–∑–∫–∞—è' if sample['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] > 80 else '–°—Ä–µ–¥–Ω—è—è', delta_color = 'normal' if sample['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] > 80 else 'inverse')
        rv = round(int(sample['–ü–æ—Å—Ç–∞–≤—â–∏–∫']))
        if str(rv) in list(supp_stat.keys()):
            col4.metric('–†–µ–π—Ç–∏–Ω–≥ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞', supp_stat[str(rv)], delta = '–í—ã—Å–æ–∫–∏–π' if supp_stat[str(rv)] in ['5‚≠ê', '4‚≠ê'] else '–ù–∏–∑–∫–∏–π', delta_color = 'normal' if supp_stat[str(rv)] in ['5‚≠ê', '4‚≠ê'] else 'inverse')
        else:
            col4.metric('–†–µ–π—Ç–∏–Ω–≥ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')


        columns_to_query =  ['–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–ú–∞—Ç–µ—Ä–∏–∞–ª']

        similar_samples = get_similar_samples(df_train, sample, columns_to_query)
        # print(similar_samples.shape)

        if len(similar_samples) < 40:
            similar_samples = get_similar_samples(df_train, sample, ['–ü–æ—Å—Ç–∞–≤—â–∏–∫'])
        if len(similar_samples) < 40:
            similar_samples = get_similar_samples(df_train, sample, ['–ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä'])

        shap_values, explainer = get_shap_values(similar_samples, model.model, cat_fts)
        feature_names = similar_samples.drop('y', axis=1).columns
        feature_names = [cols_le[x] for x in feature_names]

        st.divider()

        col1, col2 = st.columns(2)

        with col1:
            get_shap_percentage_list(shap_values[0], feature_names, threshold=1.0)

        with col2:
            cat_fts_to_draw = ['–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä', '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä',
                    '–ó–∞–≤–æ–¥', '–ó–∞–∫—É–ø–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è', '–ì—Ä—É–ø–ø–∞ –∑–∞–∫—É–ø–æ–∫', '–ë–∞–ª–∞–Ω—Å–æ–≤–∞—è –µ–¥–∏–Ω–∏—Ü–∞',
                    '–ì—Ä—É–ø–ø–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤', '–í–∞—Ä–∏–∞–Ω—Ç –ø–æ—Å—Ç–∞–≤–∫–∏']

            display_risk_info(df_train, sample, ['–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä', '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä', '–í–∞—Ä–∏–∞–Ω—Ç –ø–æ—Å—Ç–∞–≤–∫–∏', '–ú–∞—Ç–µ—Ä–∏–∞–ª'])

        st.divider() 

        # st.markdown('##### –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å–µ–º–ø–ª–∞')
        # st.session_state.
        # selected_column = st.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫', cat_fts) ### –•–£–ô–ù–Ø –ù–ï –†–ê–ë–û–¢–ê–ï–¢ –Æ–ë–Æ–õ–Ø–¢–¨ –ï–Æ–ë–ê–ì–´–Ø–ô –°–¢–†–ò–ú–õ–ò–¢ –Ø –ï–ë–ê–õ –ï–ì–û –ú–ê–¢–¨

        # st.divider()

        download(st.session_state.test)

        st.divider()

    with tab2: 
        st.divider()

        st.dataframe(df_train, height=200)

        st.divider()

        col1, col2, col3, col4 = st.columns(4)

        col1.metric('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤', df_train['–ü–æ—Å—Ç–∞–≤—â–∏–∫'].nunique())
        col2.metric('–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å—Ç–∞–≤–∫–∏', round(df_train['–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'].mean(), 2))
        col3.metric('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫', df_train[df_train['y'] == 0].shape[0])
        col4.metric('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ä–æ—á–µ–∫', df_train[df_train['y'] == 1].shape[0])

        st.divider()
        
        st.markdown('##### –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ')

        col1, col2 = st.columns(2)
        
        preds_train = pd.read_csv('preds_train.csv')
        
        y_true = preds_train["gt"]
        y_pred = preds_train["pred"]
        
        # Calculate the classification report
        class_report = classification_report(y_true, y_pred, target_names=["–í —Å—Ä–æ–∫", "–ü—Ä–æ—Å—Ä–æ—á–∫–∞"], output_dict=True)

        # Calculate the confusion matrix
        conf_matrix = confusion_matrix(y_true, y_pred)
        
        with col1:
            # Convert the classification report to a DataFrame
            df_report = pd.DataFrame(class_report).apply(lambda x: round(x, 3)).transpose()

            # Create a Plotly table
            fig = go.Figure(data=[go.Table(
                header=dict(values=['', 'Precision', 'Recall', 'F1-Score', 'Support'],
                            fill_color='paleturquoise',
                            align='center'),
                cells=dict(values=[df_report.index, 
                                df_report['precision'], 
                                df_report['recall'], 
                                df_report['f1-score'], 
                                df_report['support']],
                        # fill_color='lavender',
                        align='center'))
            ])

            fig.update_layout(title='–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏', margin=dict(b=0), autosize=False, height=250)

            # Show the plot
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown(
                """
                –ö–∞–∂–¥–∞—è –º–µ—Ç—Ä–∏–∫–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–º –æ—Ç—á–µ—Ç–µ –∏–º–µ–µ—Ç —Å–≤–æ—é —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é:

                * **–¢–æ—á–Ω–æ—Å—Ç—å (Precision):** –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è –¥–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –±—ã–ª–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–∞; —Ç–æ –µ—Å—Ç—å, —Å–∫–æ–ª—å–∫–æ –∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –∫ —Ü–µ–ª–µ–≤–æ–º—É –∫–ª–∞—Å—Å—É.

                * **–ü–æ–ª–Ω–æ—Ç–∞ (Recall):** –û—Ç—Ä–∞–∂–∞–µ—Ç, –∫–∞–∫–∞—è –¥–æ–ª—è –∏—Å—Ç–∏–Ω–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –Ω–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å—é; –æ–Ω–∞ –∏–∑–º–µ—Ä—è–µ—Ç, —Å–∫–æ–ª—å–∫–æ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.

                * **F1-–º–µ—Ä–∞ (F1-Score):** –≠—Ç–æ –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ –ø–æ–ª–Ω–æ—Ç–æ–π. –û–Ω–∞ –ø–æ–º–æ–≥–∞–µ—Ç –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –º–µ–∂–¥—É —ç—Ç–∏–º–∏ –¥–≤—É–º—è –º–µ—Ç—Ä–∏–∫–∞–º–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –æ–Ω–∏ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—ã–µ –≤–µ—Å–∞ –≤ –∑–∞–¥–∞—á–µ.

                * **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ (Support):** –≠—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ. –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, —Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –∫–∞–∂–¥—ã–π –∫–ª–∞—Å—Å.
                """
                )
        
        with col2:
            fig = px.imshow(conf_matrix,
                labels=dict(x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", y="–ò—Å—Ç–∏–Ω–∞"),
                x=["–í —Å—Ä–æ–∫", "–ü—Ä–æ—Å—Ä–æ—á–∫–∞"],
                y=["–í —Å—Ä–æ–∫", "–ü—Ä–æ—Å—Ä–æ—á–∫–∞"],
                title="–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
            for i in range(len(conf_matrix)):
                for j in range(len(conf_matrix[0])):
                    fig.add_annotation(
                        text=str(conf_matrix[i][j]),
                        x=["–í —Å—Ä–æ–∫", "–ü—Ä–æ—Å—Ä–æ—á–∫–∞"][j],
                        y=["–í —Å—Ä–æ–∫", "–ü—Ä–æ—Å—Ä–æ—á–∫–∞"][i],
                        showarrow=False,
                        font=dict(color="black"),
                        xref="x",
                        yref="y",
                        xanchor="center",
                        yanchor="middle",
                    )
            fig.update_xaxes(side="top")

            # Show the plot
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown('* –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å, \
                         –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ–π –∏ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.')
        
        st.divider()
        
        st.markdown('##### –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö')

        col1, col2 = st.columns(2)

        df_train['supp_rating'] = df_train['–ü–æ—Å—Ç–∞–≤—â–∏–∫'].apply(lambda x: supp_stat[str(x)])

        with col1:
            rating_y_count = df_train.groupby(['supp_rating'])['y'].value_counts().reset_index(name='count')

            fig = px.bar(rating_y_count, x='supp_rating', y='count', color=rating_y_count['y'].astype(str), 
                        labels={'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 'supp_rating': '–†–µ–π—Ç–∏–Ω–≥', 'color': '–°—Ç–∞—Ç—É—Å –ø–æ—Å—Ç–∞–≤–∫–∏'}, barmode='group',
                        title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö/–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞.')

            st.plotly_chart(fig, use_container_width=True)

        with col2:
            rating_len_mean = df_train.groupby(['supp_rating'])['–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'].mean().reset_index(name='mean')


            fig = px.bar(rating_len_mean, x='supp_rating', y='mean', color='supp_rating', 
                        labels={'mean': '–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', 'supp_rating': '–†–µ–π—Ç–∏–Ω–≥', 'color': '–†–µ–π—Ç–∏–Ω–≥'},
                        title='–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å—Ç–∞–≤–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞')

            st.plotly_chart(fig, use_container_width=True)

        st.divider()

        supplier_to_plot = st.select_slider('–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤:', sorted(df_train['–ü–æ—Å—Ç–∞–≤—â–∏–∫'].unique()))

        col1, col2 = st.columns(2)

        with col1:
            supp_y_count = df_train.groupby(['–ü–æ—Å—Ç–∞–≤—â–∏–∫'])['y'].value_counts()

            fig = px.bar(x=[supplier_to_plot, supplier_to_plot], y=supp_y_count[supplier_to_plot].values,
                         color=supp_y_count[supplier_to_plot].index.astype(str), barmode='group', 
                         labels={'x': '–ü–æ—Å—Ç–∞–≤—â–∏–∫', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 'color': '–°—Ç–∞—Ç—É—Å –ø–æ—Å—Ç–∞–≤–∫–∏'}, 
                         title=f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö/–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫ –¥–ª—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ {supplier_to_plot}')
            st.plotly_chart(fig, use_container_width=True)



        with col2:
            supp_mat_count = df_train.groupby(['–ü–æ—Å—Ç–∞–≤—â–∏–∫'])['–ú–∞—Ç–µ—Ä–∏–∞–ª'].value_counts()

            fig = px.pie(values=supp_mat_count[supplier_to_plot][:10].values, names=supp_mat_count[supplier_to_plot][:10].index, title=f'–¢–æ–ø 10 –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥–ª—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ {supplier_to_plot}')
            fig.update_traces(textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)


        col1, col2 = st.columns(2)


        with col1:
            fig = ff.create_distplot([df_train[(df_train['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] == supplier_to_plot) & (df_train['y'] == 0)]['–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'].values, 
                                      df_train[(df_train['–ü–æ—Å—Ç–∞–≤—â–∏–∫'] == supplier_to_plot) & (df_train['y'] == 1)]['–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'].values], 
                                     [f'–ü–æ—Å—Ç–∞–≤—â–∏–∫ = {supplier_to_plot} | –°—Ç–∞—Ç—É—Å –ø–æ—Å—Ç–∞–≤–∫–∏ = –í —Å—Ä–æ–∫', f'–ü–æ—Å—Ç–∞–≤—â–∏–∫ = {supplier_to_plot} | –°—Ç–∞—Ç—É—Å –ø–æ—Å—Ç–∞–≤–∫–∏ = –ü—Ä–æ—Å—Ä–æ—á–∫–∞'])
            fig.update_layout(title_text=f'–ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–∞–≤–∫–∏ –¥–ª—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ {supplier_to_plot}, –≥—Ä—É–ø–ø–∏—Ä—É—è –ø–æ —Å—Ç–∞—Ç—É—Å—É –ø–æ—Å—Ç–∞–≤–∫–∏')
            st.plotly_chart(fig, use_container_width=True)

            st.divider()


            # –≤—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏
            column_for_time = st.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É', cat_fts)
            unique_values = sorted(df_train[column_for_time].unique().tolist())
            # –≤—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∫–æ–ª–æ–Ω–∫–∏
            selected_value = st.select_slider('–í—ã–±–µ—Ä–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ', unique_values)
            st.plotly_chart(plot_failures_over_time(df_train, column_for_time, selected_value))

        with col2:
            sup_mat_y = df_train.groupby(['–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–ú–∞—Ç–µ—Ä–∏–∞–ª'])['y'].value_counts()

            x = sup_mat_y[supplier_to_plot][supp_mat_count[supplier_to_plot][:10].index].reset_index(name='y_count')
            x[['–ú–∞—Ç–µ—Ä–∏–∞–ª', 'y']] = x[['–ú–∞—Ç–µ—Ä–∏–∞–ª', 'y']].astype(str)
            x['–ú–∞—Ç–µ—Ä–∏–∞–ª'] = x['–ú–∞—Ç–µ—Ä–∏–∞–ª'] + '_'

            fig = px.bar(x, x='–ú–∞—Ç–µ—Ä–∏–∞–ª', y='y_count',
                        color='y', barmode='group', 
                        labels={'y_count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 'y': '–°—Ç–∞—Ç—É—Å –ø–æ—Å—Ç–∞–≤–∫–∏'}, 
                        title=f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö/–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫ –¥–ª—è —Ç–æ–ø–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ {supplier_to_plot}')
            st.plotly_chart(fig, use_container_width=True)


            st.divider()

            columns_to_group = st.multiselect('–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏', cat_fts, default=['–ü–æ—Å—Ç–∞–≤—â–∏–∫'])
            selected_values = {}

            # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–∂–µ—Ç—ã –≤—ã–±–æ—Ä–∞ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
            for column in columns_to_group:
                unique_values = sorted(df_train[column].unique().tolist())
                selected_values[column] = st.select_slider(f"–í—ã–±–µ—Ä–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è '{column}'", unique_values)

            if selected_values:
                filtered_samples = get_filtered_samples(df_train, selected_values)
                rating_y_count = filtered_samples['y'].value_counts().reset_index(name='count').rename({'index':'y'}, axis=1)

                fig = px.bar(rating_y_count, x='y', y='count', 
                    labels={'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'}, barmode='group',
                    title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö/–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤–æ–∫ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏')

                st.plotly_chart(fig, use_container_width=True)

        if selected_values:

            col1, col2 = st.columns(2)

            with col1:
                values_to_plot = filtered_samples.groupby('y')[['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ 7', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ 15', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ 30']].mean().reset_index().melt('y')
                values_to_plot['variable'] = [7, 7, 15, 15, 30, 30]
                fig = px.line(values_to_plot, x='variable', y='value', color='y', title=f'–î–∏–Ω–∞–º–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤')
                fig.update_traces(mode='markers+lines')
                fig.update_xaxes(title='–î–Ω–∏')
                fig.update_yaxes(title='–°—Ä–µ–¥–Ω–µ–µ –∫-–≤–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤')
                st.plotly_chart(fig, use_container_width=True)

            with col2:

                values_to_plot = filtered_samples.groupby('y')[['–ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ 7','–ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ 15','–ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞–≤–∫–∏ 30']].mean().reset_index().melt('y')
                values_to_plot['variable'] = [7, 7, 15, 15, 30, 30]
                fig = px.line(values_to_plot, x='variable', y='value', color='y', title=f'–î–∏–Ω–∞–º–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞—Ç –ø–æ—Å—Ç–∞–≤–∫–∏')
                fig.update_traces(mode='markers+lines')
                fig.update_xaxes(title='–î–Ω–∏')
                fig.update_yaxes(title='–°—Ä–µ–¥–Ω–µ–µ –∫-–≤–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–∞—Ç –ø–æ—Å—Ç–∞–≤–∫–∏')
                st.plotly_chart(fig, use_container_width=True)

        st.divider()

        st.button('–°–∫–∞—á–∞—Ç—å –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ê–Ω–∞–ª–∏–∑ –≤ PDF', type='primary', use_container_width=True)

        st.divider()
























